{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Finetuning GPT2 on Unseen Legal data \nVedant Shenoy | 26/04/24\n\nIntroduction:\nIn this notebook, a GPT2 model will be finetuned on textual data collected from Law StackExchange.\nThe model which has 335 million parameters will be finetuned on a dataset with 380 million parameters.","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset, Dataset\nimport re\nimport unicodedata\nimport os\nimport time\nimport datetime\n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport random\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\ntorch.manual_seed(42)\n\nfrom transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\nfrom transformers import AdamW, get_linear_schedule_with_warmup\n\nimport html\nimport json\n\nimport nltk\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2024-04-27T12:35:36.047434Z","iopub.execute_input":"2024-04-27T12:35:36.047907Z","iopub.status.idle":"2024-04-27T12:35:36.065053Z","shell.execute_reply.started":"2024-04-27T12:35:36.047871Z","shell.execute_reply":"2024-04-27T12:35:36.063572Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data\n\nThe data used for this project was sourced from [HuggingFace](https://huggingface.co/datasets/ymoslem/Law-StackExchange). The dataset contains all StackExchange legal questions and their answers up until August 2023. Every question has several replies with their associated scores. THere are a total of 24,400 rows in the dataset.\n\nTo maximise model performance while dealing with limited hardware resources, we will be using a large subset of the dataset (20,000). ","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"ymoslem/Law-StackExchange\",split=\"train[0:20000]\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T12:23:13.328108Z","iopub.execute_input":"2024-04-27T12:23:13.328948Z","iopub.status.idle":"2024-04-27T12:23:18.564883Z","shell.execute_reply.started":"2024-04-27T12:23:13.328904Z","shell.execute_reply":"2024-04-27T12:23:18.563708Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/407 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eb61addc7754a64b13e1e687e2cb38a"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 106M/106M [00:00<00:00, 132MB/s]  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daf9d0c47a844da59ade05b2b1d00faf"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-27T12:23:18.566591Z","iopub.execute_input":"2024-04-27T12:23:18.570853Z","iopub.status.idle":"2024-04-27T12:23:18.577522Z","shell.execute_reply.started":"2024-04-27T12:23:18.570814Z","shell.execute_reply":"2024-04-27T12:23:18.576315Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['question_id', 'tags', 'question_title', 'answers', 'license', 'question_body', 'link', 'score'],\n    num_rows: 20000\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data-Preprocessing\n\nOne of the most important aspect about training a LLM is providing it with good quality training data. Even if it comes at the cost of reducing the overall training data. \n\nThis project has taken a lot of inspiration from the following paper which also trains Mistral 7B model for answering legal queries: https://arxiv.org/abs/2403.03883\n\nThe first thing to do is convert the data to a dataframe to make it easier to perform preprocessing\n","metadata":{}},{"cell_type":"code","source":"df = dataset.to_pandas()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T12:23:18.580416Z","iopub.execute_input":"2024-04-27T12:23:18.581213Z","iopub.status.idle":"2024-04-27T12:23:19.039936Z","shell.execute_reply.started":"2024-04-27T12:23:18.581178Z","shell.execute_reply":"2024-04-27T12:23:19.038892Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T12:30:58.757549Z","iopub.execute_input":"2024-04-27T12:30:58.757924Z","iopub.status.idle":"2024-04-27T12:30:58.778251Z","shell.execute_reply.started":"2024-04-27T12:30:58.757895Z","shell.execute_reply":"2024-04-27T12:30:58.776978Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"   question_id                                 tags  \\\n0        94665  [criminal-law, driving, sentencing]   \n0        94665  [criminal-law, driving, sentencing]   \n0        94665  [criminal-law, driving, sentencing]   \n0        94665  [criminal-law, driving, sentencing]   \n0        94665  [criminal-law, driving, sentencing]   \n\n                                      question_title  \\\n0  Why is drunk driving causing accident punished...   \n0  Why is drunk driving causing accident punished...   \n0  Why is drunk driving causing accident punished...   \n0  Why is drunk driving causing accident punished...   \n0  Why is drunk driving causing accident punished...   \n\n                                             answers       license  \\\n0  {'answer_id': 94666, 'body': '<h3>Moral luck</...  CC BY-SA 4.0   \n0  {'answer_id': 94674, 'body': '<p>Drunk driving...  CC BY-SA 4.0   \n0  {'answer_id': 94677, 'body': '<p>Drivers are n...  CC BY-SA 4.0   \n0  {'answer_id': 94669, 'body': '<p>Have you seen...  CC BY-SA 4.0   \n0  {'answer_id': 94681, 'body': '<p><strong>The q...  CC BY-SA 4.0   \n\n                                       question_body  \\\n0  <p>When people drink and drive and then cause ...   \n0  <p>When people drink and drive and then cause ...   \n0  <p>When people drink and drive and then cause ...   \n0  <p>When people drink and drive and then cause ...   \n0  <p>When people drink and drive and then cause ...   \n\n                                                link  score  \n0  https://law.stackexchange.com/questions/94665/...     23  \n0  https://law.stackexchange.com/questions/94665/...     23  \n0  https://law.stackexchange.com/questions/94665/...     23  \n0  https://law.stackexchange.com/questions/94665/...     23  \n0  https://law.stackexchange.com/questions/94665/...     23  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question_id</th>\n      <th>tags</th>\n      <th>question_title</th>\n      <th>answers</th>\n      <th>license</th>\n      <th>question_body</th>\n      <th>link</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>94665</td>\n      <td>[criminal-law, driving, sentencing]</td>\n      <td>Why is drunk driving causing accident punished...</td>\n      <td>{'answer_id': 94666, 'body': '&lt;h3&gt;Moral luck&lt;/...</td>\n      <td>CC BY-SA 4.0</td>\n      <td>&lt;p&gt;When people drink and drive and then cause ...</td>\n      <td>https://law.stackexchange.com/questions/94665/...</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>94665</td>\n      <td>[criminal-law, driving, sentencing]</td>\n      <td>Why is drunk driving causing accident punished...</td>\n      <td>{'answer_id': 94674, 'body': '&lt;p&gt;Drunk driving...</td>\n      <td>CC BY-SA 4.0</td>\n      <td>&lt;p&gt;When people drink and drive and then cause ...</td>\n      <td>https://law.stackexchange.com/questions/94665/...</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>94665</td>\n      <td>[criminal-law, driving, sentencing]</td>\n      <td>Why is drunk driving causing accident punished...</td>\n      <td>{'answer_id': 94677, 'body': '&lt;p&gt;Drivers are n...</td>\n      <td>CC BY-SA 4.0</td>\n      <td>&lt;p&gt;When people drink and drive and then cause ...</td>\n      <td>https://law.stackexchange.com/questions/94665/...</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>94665</td>\n      <td>[criminal-law, driving, sentencing]</td>\n      <td>Why is drunk driving causing accident punished...</td>\n      <td>{'answer_id': 94669, 'body': '&lt;p&gt;Have you seen...</td>\n      <td>CC BY-SA 4.0</td>\n      <td>&lt;p&gt;When people drink and drive and then cause ...</td>\n      <td>https://law.stackexchange.com/questions/94665/...</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>94665</td>\n      <td>[criminal-law, driving, sentencing]</td>\n      <td>Why is drunk driving causing accident punished...</td>\n      <td>{'answer_id': 94681, 'body': '&lt;p&gt;&lt;strong&gt;The q...</td>\n      <td>CC BY-SA 4.0</td>\n      <td>&lt;p&gt;When people drink and drive and then cause ...</td>\n      <td>https://law.stackexchange.com/questions/94665/...</td>\n      <td>23</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":" Let's explore the data","metadata":{}},{"cell_type":"code","source":"df.answers.iloc[0][0]","metadata":{"execution":{"iopub.status.busy":"2024-04-27T12:24:09.549829Z","iopub.execute_input":"2024-04-27T12:24:09.550355Z","iopub.status.idle":"2024-04-27T12:24:09.560305Z","shell.execute_reply.started":"2024-04-27T12:24:09.550285Z","shell.execute_reply":"2024-04-27T12:24:09.559095Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'answer_id': 94666,\n 'body': '<h3>Moral luck</h3>\\n<p>You have raised the issue of <em>moral luck</em>, a long recognized problem in criminal theory. The classic expositions of this issue are by <a href=\"https://en.m.wikipedia.org/wiki/Thomas_Nagel\" rel=\"noreferrer\">Thomas Nagel</a>, in his chapter, &quot;<a href=\"https://rintintin.colorado.edu/%7Evancecd/phil1100/Nagel1.pdf\" rel=\"noreferrer\">Moral Luck</a>&quot; (1979) and <a href=\"https://en.m.wikipedia.org/wiki/Bernard_Williams\" rel=\"noreferrer\">Bernard Williams</a>, &quot;<a href=\"https://bibliotecamathom.files.wordpress.com/2012/10/williams_-_moral_luck.pdf\" rel=\"noreferrer\">Moral Luck</a>&quot; (1976). Specifically, you are describing what they call <em>outcome</em> luck, or <em>consequential</em> luck.</p>\\n<p>Driving while intoxicated vs. driving while intoxicated and causing death is not the only example where moral luck results in a distinction in punishment. Other examples are:</p>\\n<ul>\\n<li>dangerous driving vs. dangerous driving that causes death</li>\\n<li>a successful offence vs. an attempted offence (generally resulting in a maximum sentence less than that of the successful offence)</li>\\n</ul>\\n<p>Nagel writes:</p>\\n<blockquote>\\n<p>If someone has had too\\nmuch to drink and his car swerves on to the sidewalk, he can count himself morally lucky if there are no pedestrians in its path. If there were, he would\\nbe to blame for their deaths, and would probably be prosecuted for\\nmanslaughter. But if he hurts no one, although his recklessness is exactly the\\nsame, he is guilty of a far less serious legal offence and will certainly reproach\\nhimself and be reproached by others much less severely. To take another legal\\nexample, the penalty for attempted murder is less than that for successful\\nmurder – however similar the intentions and motives of the assailant may be\\nin the two cases. His degree of culpability can depend, it would seem, on\\nwhether the victim happened to be wearing a bullet-proof vest, or whether a\\nbird flew into the path of the bullet – matters beyond his control.</p>\\n<p>...</p>\\n<p>... How is it possible to be more or less culpable depending\\non whether a child gets into the path of one’s car, or a bird into the path of\\none’s bullet? Perhaps it is true that what is done depends on more than the\\nagent’s state of mind or intention. The problem then is, why is it not irrational to base moral assessment on what people do, in this broad sense? It\\namounts to holding them responsible for the contributions of fate as well as\\nfor their own – provided they have made some contribution to begin with. ... If the object of moral judgment is the person, then to hold him accountable for what he has done in the broader sense is akin to strict liability, which may have its legal uses but seems irrational as a moral position.</p>\\n</blockquote>\\n<h3>Two offered justifications for making distinctions based purely on outcome</h3>\\n<p>Two considerations often raised as justification for differential treatment based on outcome are (<a href=\"https://en.m.wikipedia.org/wiki/David_Enoch_(philosopher)\" rel=\"noreferrer\">David Enoch</a> &amp; <a href=\"https://en.m.wikipedia.org/wiki/Andrei_Marmor\" rel=\"noreferrer\">Andrei Marmor</a>, &quot;<a href=\"https://www.jstor.org/stable/27652623\" rel=\"noreferrer\">The Case against Moral Luck</a>&quot;, 26 LAW &amp; PHIL. 405 (2007), pp. 415–17)</p>\\n<ul>\\n<li>epistemological / evidential — the person who <em>actually</em> killed a person was more likely to have been driving more recklessly</li>\\n<li>the theory that the actor should have to internalize the risk, fully, when they set out on a risky activity — if they happen to kill someone, the risk of this higher punishment was part of what they should have accounted for when deciding to embark on the risky activity</li>\\n</ul>\\n<p>A couple of quotes from Enoch and Marmor:</p>\\n<blockquote>\\n<p>All other things being equal, the occurrence of an accident is plausibly considered as at least some prima facie evidence for recklessness, or indeed for a higher\\ndegree of recklessness.</p>\\n</blockquote>\\n<blockquote>\\n<p>A conception of fairness that requires\\nagents to internalize the costs of their risky activities does not\\nnecessarily reflect a view of responsibility or blameworthiness.\\nIt may simply reflect a judgment about the appropriate distribution of the costs of risky activities.</p>\\n</blockquote>\\n',\n 'score': 72}"},"metadata":{}}]},{"cell_type":"markdown","source":"As the data was collected from an online forum, every question has several replies. Which is stored in the form of List of Dictionaries where every dictionary contains a response along with some metadata. The most simple approach to this challenge would be to train the data on all the responses. As the model we have selected is an older model, we have to also consider factors such as context window. If the total text is too long, the model might not learn the proper structure behind answering a question. \n\nTherefore, for this project we have taken the approach of adding the question before every response. This will ensure that the model understands the aforementioned structure while also learning to respond in multiple ways to a single question. This also helps increase the amount of training data which is crucial as the model is fairly large. But this does come at the cost of compute resources","metadata":{}},{"cell_type":"code","source":"df = df.explode('answers')","metadata":{"execution":{"iopub.status.busy":"2024-04-27T12:30:37.021080Z","iopub.execute_input":"2024-04-27T12:30:37.021489Z","iopub.status.idle":"2024-04-27T12:30:37.091947Z","shell.execute_reply.started":"2024-04-27T12:30:37.021461Z","shell.execute_reply":"2024-04-27T12:30:37.090653Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T12:30:53.247785Z","iopub.execute_input":"2024-04-27T12:30:53.248375Z","iopub.status.idle":"2024-04-27T12:30:53.270894Z","shell.execute_reply.started":"2024-04-27T12:30:53.248336Z","shell.execute_reply":"2024-04-27T12:30:53.269008Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   question_id                                 tags  \\\n0        94665  [criminal-law, driving, sentencing]   \n0        94665  [criminal-law, driving, sentencing]   \n0        94665  [criminal-law, driving, sentencing]   \n0        94665  [criminal-law, driving, sentencing]   \n0        94665  [criminal-law, driving, sentencing]   \n\n                                      question_title  \\\n0  Why is drunk driving causing accident punished...   \n0  Why is drunk driving causing accident punished...   \n0  Why is drunk driving causing accident punished...   \n0  Why is drunk driving causing accident punished...   \n0  Why is drunk driving causing accident punished...   \n\n                                             answers       license  \\\n0  {'answer_id': 94666, 'body': '<h3>Moral luck</...  CC BY-SA 4.0   \n0  {'answer_id': 94674, 'body': '<p>Drunk driving...  CC BY-SA 4.0   \n0  {'answer_id': 94677, 'body': '<p>Drivers are n...  CC BY-SA 4.0   \n0  {'answer_id': 94669, 'body': '<p>Have you seen...  CC BY-SA 4.0   \n0  {'answer_id': 94681, 'body': '<p><strong>The q...  CC BY-SA 4.0   \n\n                                       question_body  \\\n0  <p>When people drink and drive and then cause ...   \n0  <p>When people drink and drive and then cause ...   \n0  <p>When people drink and drive and then cause ...   \n0  <p>When people drink and drive and then cause ...   \n0  <p>When people drink and drive and then cause ...   \n\n                                                link  score  \n0  https://law.stackexchange.com/questions/94665/...     23  \n0  https://law.stackexchange.com/questions/94665/...     23  \n0  https://law.stackexchange.com/questions/94665/...     23  \n0  https://law.stackexchange.com/questions/94665/...     23  \n0  https://law.stackexchange.com/questions/94665/...     23  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question_id</th>\n      <th>tags</th>\n      <th>question_title</th>\n      <th>answers</th>\n      <th>license</th>\n      <th>question_body</th>\n      <th>link</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>94665</td>\n      <td>[criminal-law, driving, sentencing]</td>\n      <td>Why is drunk driving causing accident punished...</td>\n      <td>{'answer_id': 94666, 'body': '&lt;h3&gt;Moral luck&lt;/...</td>\n      <td>CC BY-SA 4.0</td>\n      <td>&lt;p&gt;When people drink and drive and then cause ...</td>\n      <td>https://law.stackexchange.com/questions/94665/...</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>94665</td>\n      <td>[criminal-law, driving, sentencing]</td>\n      <td>Why is drunk driving causing accident punished...</td>\n      <td>{'answer_id': 94674, 'body': '&lt;p&gt;Drunk driving...</td>\n      <td>CC BY-SA 4.0</td>\n      <td>&lt;p&gt;When people drink and drive and then cause ...</td>\n      <td>https://law.stackexchange.com/questions/94665/...</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>94665</td>\n      <td>[criminal-law, driving, sentencing]</td>\n      <td>Why is drunk driving causing accident punished...</td>\n      <td>{'answer_id': 94677, 'body': '&lt;p&gt;Drivers are n...</td>\n      <td>CC BY-SA 4.0</td>\n      <td>&lt;p&gt;When people drink and drive and then cause ...</td>\n      <td>https://law.stackexchange.com/questions/94665/...</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>94665</td>\n      <td>[criminal-law, driving, sentencing]</td>\n      <td>Why is drunk driving causing accident punished...</td>\n      <td>{'answer_id': 94669, 'body': '&lt;p&gt;Have you seen...</td>\n      <td>CC BY-SA 4.0</td>\n      <td>&lt;p&gt;When people drink and drive and then cause ...</td>\n      <td>https://law.stackexchange.com/questions/94665/...</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>94665</td>\n      <td>[criminal-law, driving, sentencing]</td>\n      <td>Why is drunk driving causing accident punished...</td>\n      <td>{'answer_id': 94681, 'body': '&lt;p&gt;&lt;strong&gt;The q...</td>\n      <td>CC BY-SA 4.0</td>\n      <td>&lt;p&gt;When people drink and drive and then cause ...</td>\n      <td>https://law.stackexchange.com/questions/94665/...</td>\n      <td>23</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Next step, we will drop null values","metadata":{}},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T12:35:28.198380Z","iopub.execute_input":"2024-04-27T12:35:28.198771Z","iopub.status.idle":"2024-04-27T12:35:28.232900Z","shell.execute_reply.started":"2024-04-27T12:35:28.198742Z","shell.execute_reply":"2024-04-27T12:35:28.231766Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"The response body contains a lot of unwanted information in the form of HTML entities and formating characters. It is essential to properly remove them before proceding. We will also be performing text normalisation so that the LLM does not mislearn representations of words which look similar to us but have different unicode representations.","metadata":{}},{"cell_type":"code","source":"def clean_text_answer(html_text):\n    # Remove HTML tags    \n    html_text = html_text[\"body\"]\n    clean_text = re.sub(r'<.*?>', '', html_text)\n    # Decode HTML entities    \n    clean_text = html.unescape(clean_text)\n    # Remove newline characters\n    clean_text = clean_text.replace('\\n', ' ')\n    # Remove multiple whitespaces\n    clean_text = re.sub(r'\\s+', ' ', clean_text).strip()\n    #Normalise the data\n    clean_text = unicodedata.normalize('NFKC',clean_text)\n    \n    return clean_text\n\ndf[\"answers\"] = df[\"answers\"].apply(clean_text_answer)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T12:35:41.245469Z","iopub.execute_input":"2024-04-27T12:35:41.245888Z","iopub.status.idle":"2024-04-27T12:35:46.822230Z","shell.execute_reply.started":"2024-04-27T12:35:41.245855Z","shell.execute_reply":"2024-04-27T12:35:46.821240Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df[\"answers\"].iloc[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-27T12:36:07.784280Z","iopub.execute_input":"2024-04-27T12:36:07.784665Z","iopub.status.idle":"2024-04-27T12:36:07.792981Z","shell.execute_reply.started":"2024-04-27T12:36:07.784637Z","shell.execute_reply":"2024-04-27T12:36:07.791627Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'Moral luck You have raised the issue of moral luck, a long recognized problem in criminal theory. The classic expositions of this issue are by Thomas Nagel, in his chapter, \"Moral Luck\" (1979) and Bernard Williams, \"Moral Luck\" (1976). Specifically, you are describing what they call outcome luck, or consequential luck. Driving while intoxicated vs. driving while intoxicated and causing death is not the only example where moral luck results in a distinction in punishment. Other examples are: dangerous driving vs. dangerous driving that causes death a successful offence vs. an attempted offence (generally resulting in a maximum sentence less than that of the successful offence) Nagel writes: If someone has had too much to drink and his car swerves on to the sidewalk, he can count himself morally lucky if there are no pedestrians in its path. If there were, he would be to blame for their deaths, and would probably be prosecuted for manslaughter. But if he hurts no one, although his recklessness is exactly the same, he is guilty of a far less serious legal offence and will certainly reproach himself and be reproached by others much less severely. To take another legal example, the penalty for attempted murder is less than that for successful murder – however similar the intentions and motives of the assailant may be in the two cases. His degree of culpability can depend, it would seem, on whether the victim happened to be wearing a bullet-proof vest, or whether a bird flew into the path of the bullet – matters beyond his control. ... ... How is it possible to be more or less culpable depending on whether a child gets into the path of one’s car, or a bird into the path of one’s bullet? Perhaps it is true that what is done depends on more than the agent’s state of mind or intention. The problem then is, why is it not irrational to base moral assessment on what people do, in this broad sense? It amounts to holding them responsible for the contributions of fate as well as for their own – provided they have made some contribution to begin with. ... If the object of moral judgment is the person, then to hold him accountable for what he has done in the broader sense is akin to strict liability, which may have its legal uses but seems irrational as a moral position. Two offered justifications for making distinctions based purely on outcome Two considerations often raised as justification for differential treatment based on outcome are (David Enoch & Andrei Marmor, \"The Case against Moral Luck\", 26 LAW & PHIL. 405 (2007), pp. 415–17) epistemological / evidential — the person who actually killed a person was more likely to have been driving more recklessly the theory that the actor should have to internalize the risk, fully, when they set out on a risky activity — if they happen to kill someone, the risk of this higher punishment was part of what they should have accounted for when deciding to embark on the risky activity A couple of quotes from Enoch and Marmor: All other things being equal, the occurrence of an accident is plausibly considered as at least some prima facie evidence for recklessness, or indeed for a higher degree of recklessness. A conception of fairness that requires agents to internalize the costs of their risky activities does not necessarily reflect a view of responsibility or blameworthiness. It may simply reflect a judgment about the appropriate distribution of the costs of risky activities.'"},"metadata":{}}]},{"cell_type":"markdown","source":"We now perform similar text cleaning for both question_body and question_text columns","metadata":{}},{"cell_type":"code","source":"def clean_text_question(html_text):\n    # Remove HTML tags\n    clean_text = re.sub(r'<.*?>', '', html_text)\n    # Decode HTML entities\n    clean_text = html.unescape(clean_text)\n    # Remove newline characters\n    clean_text = clean_text.replace('\\n', ' ')\n    # Remove multiple whitespaces\n    clean_text = re.sub(r'\\s+', ' ', clean_text).strip()\n    \n    clean_text = unicodedata.normalize('NFKC',clean_text)\n    \n    return clean_text\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T06:11:53.279817Z","iopub.execute_input":"2024-04-27T06:11:53.280530Z","iopub.status.idle":"2024-04-27T06:11:53.285914Z","shell.execute_reply.started":"2024-04-27T06:11:53.280500Z","shell.execute_reply":"2024-04-27T06:11:53.284940Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df[\"question_body\"] = df[\"question_body\"].apply(clean_text_question)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T06:11:54.138248Z","iopub.execute_input":"2024-04-27T06:11:54.139002Z","iopub.status.idle":"2024-04-27T06:11:56.770380Z","shell.execute_reply.started":"2024-04-27T06:11:54.138957Z","shell.execute_reply":"2024-04-27T06:11:56.769560Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df[\"question_title\"] = df[\"question_title\"].apply(clean_text_question)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T06:11:56.772101Z","iopub.execute_input":"2024-04-27T06:11:56.772435Z","iopub.status.idle":"2024-04-27T06:11:57.097345Z","shell.execute_reply.started":"2024-04-27T06:11:56.772405Z","shell.execute_reply":"2024-04-27T06:11:57.096375Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Finally, we combine everything in order to generate training data.","metadata":{}},{"cell_type":"code","source":"df[\"training_text\"] = df[\"question_title\"]+df[\"question_body\"]+df[\"answers\"]","metadata":{"execution":{"iopub.status.busy":"2024-04-27T06:11:57.098763Z","iopub.execute_input":"2024-04-27T06:11:57.099076Z","iopub.status.idle":"2024-04-27T06:11:57.196738Z","shell.execute_reply.started":"2024-04-27T06:11:57.099051Z","shell.execute_reply":"2024-04-27T06:11:57.195644Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_text = df.training_text.copy()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T06:11:57.198423Z","iopub.execute_input":"2024-04-27T06:11:57.198719Z","iopub.status.idle":"2024-04-27T06:11:57.209714Z","shell.execute_reply.started":"2024-04-27T06:11:57.198694Z","shell.execute_reply":"2024-04-27T06:11:57.208846Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_text","metadata":{"execution":{"iopub.status.busy":"2024-04-27T06:11:57.349790Z","iopub.execute_input":"2024-04-27T06:11:57.350190Z","iopub.status.idle":"2024-04-27T06:11:57.359438Z","shell.execute_reply.started":"2024-04-27T06:11:57.350158Z","shell.execute_reply":"2024-04-27T06:11:57.358300Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"0        Why is drunk driving causing accident punished...\n0        Why is drunk driving causing accident punished...\n0        Why is drunk driving causing accident punished...\n0        Why is drunk driving causing accident punished...\n0        Why is drunk driving causing accident punished...\n                               ...                        \n19996    Who has jurisdiction over civilian crimes on a...\n19997    Can identification be confirmed over a mobile ...\n19998    In the USA, how is a war officially ended from...\n19999    How to freelance in the UK without violating t...\n19999    How to freelance in the UK without violating t...\nName: training_text, Length: 31747, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Training\n\nWe need to initialise a GPT-2 tokenizer with custom tokens for the beginning (bos_token), end (eos_token), and padding (pad_token) of sequences.","metadata":{}},{"cell_type":"code","source":"tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We set batch_size of 4 which is the number of training examples used in one iteration of training.\nbatch_size = 4","metadata":{"execution":{"iopub.status.busy":"2024-04-27T06:12:12.699418Z","iopub.execute_input":"2024-04-27T06:12:12.699795Z","iopub.status.idle":"2024-04-27T06:12:12.704131Z","shell.execute_reply.started":"2024-04-27T06:12:12.699767Z","shell.execute_reply":"2024-04-27T06:12:12.703160Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"As we are using a custom data, we need to develop a dataset class. During initialisation, it tokenises each text in the list, prepending and appending special tokens (<|startoftext|> and <|endoftext|>), and truncates or pads the sequences to fit within the specified max_length.","metadata":{}},{"cell_type":"code","source":"class GPT2Dataset(Dataset):\n\n    def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n\n        self.tokenizer = tokenizer\n        self.input_ids = []\n        self.attn_masks = []\n\n        for txt in txt_list:\n\n            encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n\n            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.attn_masks[idx] ","metadata":{"execution":{"iopub.status.busy":"2024-04-27T06:12:16.753701Z","iopub.execute_input":"2024-04-27T06:12:16.754485Z","iopub.status.idle":"2024-04-27T06:12:16.761460Z","shell.execute_reply.started":"2024-04-27T06:12:16.754452Z","shell.execute_reply":"2024-04-27T06:12:16.760485Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"dataset = GPT2Dataset(train_text, tokenizer, max_length=768)\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(dataset))\nval_size = len(dataset) - train_size\n\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\nprint('{:>5,} training samples'.format(train_size))\nprint('{:>5,} validation samples'.format(val_size))","metadata":{"execution":{"iopub.status.busy":"2024-04-27T06:12:18.838539Z","iopub.execute_input":"2024-04-27T06:12:18.839181Z","iopub.status.idle":"2024-04-27T06:15:13.659103Z","shell.execute_reply.started":"2024-04-27T06:12:18.839150Z","shell.execute_reply":"2024-04-27T06:15:13.658130Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"28,572 training samples\n3,175 validation samples\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Develop dataloaders","metadata":{}},{"cell_type":"code","source":"train_dataloader = DataLoader(\n            train_dataset,  # The training samples.\n            sampler = RandomSampler(train_dataset), # Select batches randomly\n            batch_size = batch_size # Trains with this batch size.\n        )\n\n# For validation the order doesn't matter, so we'll just read them sequentially.\nvalidation_dataloader = DataLoader(\n            val_dataset, # The validation samples.\n            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n            batch_size = batch_size # Evaluate with this batch size.\n        )","metadata":{"execution":{"iopub.status.busy":"2024-04-27T06:15:13.660886Z","iopub.execute_input":"2024-04-27T06:15:13.661208Z","iopub.status.idle":"2024-04-27T06:15:13.666459Z","shell.execute_reply.started":"2024-04-27T06:15:13.661183Z","shell.execute_reply":"2024-04-27T06:15:13.665518Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"We configure a GPT-2 model for language modeling tasks by loading its configuration with output_hidden_states=False to disable the output of hidden states during inference. It then instantiates the model using this configuration and moves it to the GPU for faster computation.","metadata":{}},{"cell_type":"code","source":"configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n\n# instantiate the model\nmodel = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n\n# Tell pytorch to run this model on the GPU.\ndevice = torch.device(\"cuda\")\n\nmodel.cuda()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T08:28:45.495838Z","iopub.execute_input":"2024-04-27T08:28:45.496221Z","iopub.status.idle":"2024-04-27T08:28:47.003550Z","shell.execute_reply.started":"2024-04-27T08:28:45.496192Z","shell.execute_reply":"2024-04-27T08:28:47.002545Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50259, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# some default parameters \nepochs = 1\nlearning_rate = 6e-4\nwarmup_steps = 1e2\nepsilon = 1e-8\n\n# this produces sample output every 1000 steps\n\nsample_every = 1000","metadata":{"execution":{"iopub.status.busy":"2024-04-27T08:28:47.880882Z","iopub.execute_input":"2024-04-27T08:28:47.881263Z","iopub.status.idle":"2024-04-27T08:28:47.885897Z","shell.execute_reply.started":"2024-04-27T08:28:47.881235Z","shell.execute_reply":"2024-04-27T08:28:47.884863Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \noptimizer = AdamW(model.parameters(),\n                  lr = learning_rate,\n                  eps = epsilon\n                )","metadata":{"execution":{"iopub.status.busy":"2024-04-27T08:28:48.720461Z","iopub.execute_input":"2024-04-27T08:28:48.721298Z","iopub.status.idle":"2024-04-27T08:28:48.728927Z","shell.execute_reply.started":"2024-04-27T08:28:48.721267Z","shell.execute_reply":"2024-04-27T08:28:48.727942Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Total number of training steps is [number of batches] x [number of epochs]. \ntotal_steps = len(train_dataloader) * epochs\n\n# Create the learning rate scheduler.\n# This changes the learning rate as the training loop progresses\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps = warmup_steps, \n                                            num_training_steps = total_steps)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T08:28:49.241274Z","iopub.execute_input":"2024-04-27T08:28:49.241646Z","iopub.status.idle":"2024-04-27T08:28:49.247813Z","shell.execute_reply.started":"2024-04-27T08:28:49.241616Z","shell.execute_reply":"2024-04-27T08:28:49.246926Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def format_time(elapsed):\n    return str(datetime.timedelta(seconds=int(round((elapsed)))))","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:20:32.930616Z","iopub.execute_input":"2024-04-27T10:20:32.931000Z","iopub.status.idle":"2024-04-27T10:20:32.935831Z","shell.execute_reply.started":"2024-04-27T10:20:32.930947Z","shell.execute_reply":"2024-04-27T10:20:32.934807Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"total_t0 = time.time()\n\ntraining_stats = []\n\nmodel = model.to(device)\n\nfor epoch_i in range(0, epochs):\n\n    # ========================================\n    #               Training\n    # ========================================\n\n    print(\"\")\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n    print('Training...')\n\n    t0 = time.time()\n\n    total_train_loss = 0\n\n    model.train()\n\n    for step, batch in enumerate(train_dataloader):\n\n        b_input_ids = batch[0].to(device)\n        b_labels = batch[0].to(device)\n        b_masks = batch[1].to(device)\n\n        model.zero_grad()        \n\n        outputs = model(  b_input_ids,\n                          labels=b_labels, \n                          attention_mask = b_masks,\n                          token_type_ids=None\n                        )\n\n        loss = outputs[0]  \n\n        batch_loss = loss.item()\n        total_train_loss += batch_loss\n\n        # Get sample every x batches.\n        if step % sample_every == 0 and not step == 0:\n\n            elapsed = format_time(time.time() - t0)\n            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n\n            model.eval()\n\n            sample_outputs = model.generate(\n                                    bos_token_id=random.randint(1,30000),\n                                    do_sample=True,   \n                                    top_k=50, \n                                    max_length = 200,\n                                    top_p=0.95, \n                                    num_return_sequences=1\n                                )\n            for i, sample_output in enumerate(sample_outputs):\n                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n            \n            model.train()\n\n        loss.backward()\n\n        optimizer.step()\n\n        scheduler.step()\n\n    # Calculate the average loss over all of the batches.\n    avg_train_loss = total_train_loss / len(train_dataloader)       \n    \n    # Measure how long this epoch took.\n    training_time = format_time(time.time() - t0)\n\n    print(\"\")\n    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n    print(\"  Training epoch took: {:}\".format(training_time))\n        \n    # ========================================\n    #               Validation\n    # ========================================\n\n    print(\"\")\n    print(\"Running Validation...\")\n\n    t0 = time.time()\n\n    model.eval()\n\n    total_eval_loss = 0\n    nb_eval_steps = 0\n\n    # Evaluate data for one epoch\n    for batch in validation_dataloader:\n        \n        b_input_ids = batch[0].to(device)\n        b_labels = batch[0].to(device)\n        b_masks = batch[1].to(device)\n        \n        with torch.no_grad():        \n\n            outputs  = model(b_input_ids, \n                             attention_mask = b_masks,\n                            labels=b_labels)\n          \n            loss = outputs[0]  \n            \n        batch_loss = loss.item()\n        total_eval_loss += batch_loss        \n\n    avg_val_loss = total_eval_loss / len(validation_dataloader)\n    \n    validation_time = format_time(time.time() - t0)    \n\n    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n    print(\"  Validation took: {:}\".format(validation_time))\n\n    # Record all statistics from this epoch.\n    training_stats.append(\n        {\n            'epoch': epoch_i + 1,\n            'Training Loss': avg_train_loss,\n            'Valid. Loss': avg_val_loss,\n            'Training Time': training_time,\n            'Validation Time': validation_time\n        }\n    )\n\nprint(\"\")\nprint(\"Training complete!\")\nprint(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))","metadata":{"execution":{"iopub.status.busy":"2024-04-27T08:28:50.270040Z","iopub.execute_input":"2024-04-27T08:28:50.270850Z","iopub.status.idle":"2024-04-27T09:35:10.285837Z","shell.execute_reply.started":"2024-04-27T08:28:50.270822Z","shell.execute_reply":"2024-04-27T09:35:10.284914Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"\n======== Epoch 1 / 1 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"  Batch 1,000  of  7,143. Loss: 1.678596019744873.   Elapsed: 0:08:56.\n0:  valveIs it illegal for a non-state person to use fake documents to get a job on a job in another state?I am a professional photographer. I'm not a lawyer but I've studied at universities. I live in Maryland but I'm not employed by another state. The issue I'm facing is not that someone would have obtained my work (which is not legally a crime), but rather that if they did, what do the laws actually look like for that? Is the fake work illegal if it is created by someone other than my employer? If not, is there some sort of affirmative defense against it? Is there some sort of statutory defense against it?I am a professional photographer. I'm not a lawyer but I'm a programmer. I've studied at universities. I live in Maryland but I'm not employed by another state. The issue I'm facing is not that someone would have obtained my work (which is not legally a crime), but rather that if they did, what\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"  Batch 2,000  of  7,143. Loss: 1.3311100006103516.   Elapsed: 0:17:54.\n0:  establishedHow can a university legally charge the university to cover costs?A private university is obligated to pay for the costs of providing free legal representation on campus. How can a University legally charge for legal representation on campus? Suppose the university is required to provide a website to students and staff that is designed for a college student (they are free to do that). Then the university cannot charge money for attorneys or any sort of service for students (they are free to do that). What exactly does this say about costs? If students do not need a lawyer, then how can they justify it? Also, how can one claim to own any university costs on their own? So, assuming you can show money is in addition to paying for an attorney, then you can claim to be in a state of Washington, OR Oregon. How can this affect your tuition? How can one claim to take some state's public libraries/public transportation costs? What are the chances of them using your university tuition money for legal counsel\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"  Batch 3,000  of  7,143. Loss: 2.1925065517425537.   Elapsed: 0:26:52.\n0: ervedMust it be legal for you to copy your text and email/fax?My wife is allergic to electric electricity so she takes a taxi to a pub, where the electricity is turned on. When the electricity fails, it can damage her eye, and it is impossible to read. However, she is very lucky not to be allergic to electric electricity, so she does not have any troubles with that. Given that this is not a private situation, I can understand why it might not work. It would require a licence and the taxi driver would need to sign them, etc. It could be worth hiring a lawyer - and would be cheaper than hiring a surgeon to do it, since she would be getting a better bill from the taxi. If the taxi driver cannot verify your identity, then there may be no problems - the taxi driver does need proof from you. My only concern would be that your wife will be physically harmed, and if she cannot speak to you, there is no way to get\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"  Batch 4,000  of  7,143. Loss: 1.2311097383499146.   Elapsed: 0:35:50.\n0:  murdersAre there specific legal requirements for the UK to be \"reasonable\" under the GDPR in this case?GDPR Article 5(2) and Article 7(1) say that \"processing activities should not be done without specific legal basis\". If the data subject, without any such legal basis, wishes to delete data relating to an offence (for example, fraud), is the data subject entitled to the full legal right to delete all the personal data of the data subject? Or is this limited to the law of the case? Or does the data subject's right to erasure come only for the purposes stated by Article 8(2)(b)? Or is this limited to the general procedure that applies when processing activities are carried out for legal purpose. Or does the data subject's right to erasure also come only for the purposes stated by Article 6(3)? Or does the data subject's right to erasure come only for the purposes stated by Article 7(2)(a)? Or does the\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"  Batch 5,000  of  7,143. Loss: 1.4661880731582642.   Elapsed: 0:44:48.\n0:  minsHow can US President Obama be punished for lying in the US Senate?In the United States Senate he has been lying to the US Senate about the contents of classified communication regarding US intelligence agency personnel. However, he does not have standing to bring criminal charges against the person. He is not allowed to lie during this time. His statements about this nature were clearly a violation of the First Amendment and have gone against the rules of the Senate. How can the US President be punished for lying in the U.S Senate? Could he be sued for this? What if there is a pattern of dishonesty on the Senate floor that is not intentional but not intentional?The Constitution gives Congress the power to impeach the President for any act or omission, in case it deems that the President lied on oath, and if it deemed he was lying in his own words, and if it did, it could still prosecute him, so long as the lie in the speech did not appear to fall under the First Amendment\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"  Batch 6,000  of  7,143. Loss: 1.394681692123413.   Elapsed: 0:53:46.\n0: attleHow can one prove someone is innocent, as is most common and I'm sure is not the case?A recent comment by @user6726 states: There is the \"legal\" question, whether any evidence has been offered by a company that it did not have access to (or does not actually know of) the information that was uncovered. It seems like the relevant law states that a company can charge damages to victims of a crime if a person (or a person) committed a crime but a person did not act in the way that could reasonably have been committed. I.e., if there was no evidence that a defendant is guilty and there was no reasonable expectation of privacy or safety of anyone, then can a person say that he/she is not guilty and there was no expectation of privacy or safety of anyone but a person who does not act in the way that could reasonably have been committed (if there were no evidence that the defendant is guilty and there was no reasonable expectation of privacy\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"  Batch 7,000  of  7,143. Loss: 2.2902512550354004.   Elapsed: 1:02:44.\n0:  ConfederWhy is there no \"right to a lawyer?\"I know that the \"right to a lawyer\" was only used to protect some people from legal action but what makes a law abiding citizen not defend a legal one from legal action? What's the reason why no person is forced to be a lawyer? Is this because the law is not written to protect everyone who represents others in civil cases? And if it is, why's a lawyer considered to be a \"rights-in-the-law\"? I'm from India.The \"right to a lawyer\" is a legal right that can be waived by the right-of-procedure, or a specific type of right, depending on the case. A contract between two parties states the legal rights of each. It's possible that the contract might contain \"exception\" which will prevent a future court to enforce the contract, but if the contract contains an exception to this, the court will usually enforce it. In this case, the\n\n  Average training loss: 1.94\n  Training epoch took: 1:04:03\n\nRunning Validation...\n  Validation Loss: 1.73\n  Validation took: 0:02:17\n\nTraining complete!\nTotal training took 1:06:20 (h:mm:ss)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a DataFrame from our training statistics.\ndf_stats = pd.DataFrame(data=training_stats)\n\n# Use the 'epoch' as the row index.\ndf_stats = df_stats.set_index('epoch')\n\ndf_stats","metadata":{"execution":{"iopub.status.busy":"2024-04-27T09:36:21.893297Z","iopub.execute_input":"2024-04-27T09:36:21.893863Z","iopub.status.idle":"2024-04-27T09:36:21.905931Z","shell.execute_reply.started":"2024-04-27T09:36:21.893833Z","shell.execute_reply":"2024-04-27T09:36:21.905041Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"       Training Loss  Valid. Loss Training Time Validation Time\nepoch                                                          \n1           1.940416     1.729608       1:04:03         0:02:17","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Training Loss</th>\n      <th>Valid. Loss</th>\n      <th>Training Time</th>\n      <th>Validation Time</th>\n    </tr>\n    <tr>\n      <th>epoch</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1.940416</td>\n      <td>1.729608</td>\n      <td>1:04:03</td>\n      <td>0:02:17</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Trial Run","metadata":{}},{"cell_type":"code","source":"model.eval()\n\nprompt = \"<|startoftext|> What is something that will land me in prison?\"\n\ngenerated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\ngenerated = generated.to(device)\n\nprint(generated)\n\nsample_outputs = model.generate(\n                                generated, \n                                #bos_token_id=random.randint(1,30000),\n                                do_sample=True,   \n                                top_k=50, \n                                max_length = 150,\n                                top_p=0.95, \n                                num_return_sequences=1,\n                                )\n\nfor i, sample_output in enumerate(sample_outputs):\n    print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:22:04.501053Z","iopub.execute_input":"2024-04-27T10:22:04.501991Z","iopub.status.idle":"2024-04-27T10:22:06.216961Z","shell.execute_reply.started":"2024-04-27T10:22:04.501947Z","shell.execute_reply":"2024-04-27T10:22:06.216043Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"tensor([[50257,  1867,   318,  1223,   326,   481,  1956,   502,   287,  3770,\n            30]], device='cuda:0')\n0:  What is something that will land me in prison?I can see why many people will want to go to prison. However, I will soon find myself in prison! This is in Germany (and is not legal for me in my home country) What is the situation like for those who would like to go to prison? Would they be able to serve as a witness? If the witness lives in Germany, then they will be able to testify. If they don't, then they will be in legal trouble. And then they are in trouble later? If the witness lives in France, there is no legal trouble but France could sue for money damages. They would be a party in the lawsuit in Germany if the French government wanted to bring the case\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"output_dir = './model_save/'\n\n# Create output directory if needed\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\nprint(\"Saving model to %s\" % output_dir)\n\n# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n# They can then be reloaded using `from_pretrained()`\nmodel_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\nmodel_to_save.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T09:39:54.148603Z","iopub.execute_input":"2024-04-27T09:39:54.149001Z","iopub.status.idle":"2024-04-27T09:39:55.290685Z","shell.execute_reply.started":"2024-04-27T09:39:54.148948Z","shell.execute_reply":"2024-04-27T09:39:55.289771Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Saving model to ./model_save/\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"('./model_save/tokenizer_config.json',\n './model_save/special_tokens_map.json',\n './model_save/vocab.json',\n './model_save/merges.txt',\n './model_save/added_tokens.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"!pip install -U evaluate","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:24:34.080527Z","iopub.execute_input":"2024-04-27T10:24:34.081305Z","iopub.status.idle":"2024-04-27T10:24:47.964820Z","shell.execute_reply.started":"2024-04-27T10:24:34.081276Z","shell.execute_reply":"2024-04-27T10:24:47.963666Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nCollecting responses<0.19 (from evaluate)\n  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\nInstalling collected packages: responses, evaluate\nSuccessfully installed evaluate-0.4.1 responses-0.18.0\n","output_type":"stream"}]},{"cell_type":"code","source":"def generate_text(prompt,num_return_sequences=1):\n    # Initialize the model and tokenizer)\n    model.eval()\n\n    # Prepare the input\n    input_text = \"<|startoftext|> \" + prompt\n    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n\n    # Generate the output\n    sample_outputs = model.generate(\n        inputs,\n        do_sample=True,\n        top_k=50,\n        max_length=150,\n        top_p=0.95,\n        num_return_sequences=num_return_sequences,\n    )\n\n    # Decode and return the generated text\n    generated_text = []\n    for output in sample_outputs:\n        generated_text.append(tokenizer.decode(output, skip_special_tokens=True))\n    return generated_text","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:40:54.686622Z","iopub.execute_input":"2024-04-27T10:40:54.687446Z","iopub.status.idle":"2024-04-27T10:40:54.693877Z","shell.execute_reply.started":"2024-04-27T10:40:54.687413Z","shell.execute_reply":"2024-04-27T10:40:54.692875Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"predictions = generate_text(\"What is the punishment for drunk driving?\",5)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:35:40.170830Z","iopub.execute_input":"2024-04-27T10:35:40.171559Z","iopub.status.idle":"2024-04-27T10:35:42.102237Z","shell.execute_reply.started":"2024-04-27T10:35:40.171525Z","shell.execute_reply":"2024-04-27T10:35:42.101384Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"from evaluate import load\nperplexity = load(\"perplexity\", module_type=\"metric\")\nresults = perplexity.compute(predictions=predictions, model_id='gpt2')","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:35:46.272268Z","iopub.execute_input":"2024-04-27T10:35:46.273058Z","iopub.status.idle":"2024-04-27T10:35:47.982132Z","shell.execute_reply.started":"2024-04-27T10:35:46.273012Z","shell.execute_reply":"2024-04-27T10:35:47.981336Z"},"trusted":true},"execution_count":77,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3929a95846d64bdeacd82986efd911a4"}},"metadata":{}}]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2024-04-27T10:35:52.357496Z","iopub.execute_input":"2024-04-27T10:35:52.357851Z","iopub.status.idle":"2024-04-27T10:35:52.363917Z","shell.execute_reply.started":"2024-04-27T10:35:52.357824Z","shell.execute_reply":"2024-04-27T10:35:52.362986Z"},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"{'perplexities': [18.795846939086914,\n  18.251562118530273,\n  12.350462913513184,\n  11.93504810333252,\n  13.493307113647461],\n 'mean_perplexity': 14.96524543762207}"},"metadata":{}}]},{"cell_type":"markdown","source":"The model has a mean perplexity of 14.96. This score is still higher compared to some of the SoTA models we use nowadays. But it is still a repectable number. \n","metadata":{}},{"cell_type":"markdown","source":"## Conclusion\n\nThis notebook successfully trained a GPT-2 model on data that wasnt present in its training data. The model also performed well and is capable of generating coherent replies indicated by its perplexity metric of 14.96. Some things that can be improved is the total number of the epochs. Due to time constraints, the total number of epochs was set to 1. Going forward the number of epochs can easily be increased for better performance.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}